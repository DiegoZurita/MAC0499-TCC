%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101/183146

%% ------------------------------------------------------------------------- %%
\chapter{Ambiente e dados}
\label{cap:data}

Este capítulo mostra o ambiente que foi usado para realizar as simulações de ataque,
coletar os logs e treinar os modelos. Além disso, também será explicado como os logs 
foram coletados e processados.

Alguns dos itens foram inspirados no trabalho de conclusão de curso "Análise de 
Desempenho de Computadores de Baixo Custo em um Sistema de Detecção de Intrusão" de 
Lucas Seiki Oshiro \cite{tcc:lucas}.

O ambiente aqui mostrado pode ser visto na Figura \ref{fig:arquitetura_total}. Na máquina pessoal foram 
criadas duas máquinas virtuais para simular os ataques, o Google Colab 
usado para avaliar, treinar e compartilhar os modelos e por fim o Raspberry Pi e o Macbook 
para rodar os experimentos.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figuras/arquitetura_total.png}
    \caption{Infraestrutura usada neste trabalho. \label{fig:arquitetura_total}}
\end{figure}


\section{Máquinas}

\subsection{Máquinas físicas}

Neste trabalho, duas máquinas físicas foram utilizadas: um desktop e um notebook, além do ambiente Google Colab. 

\begin{itemize}
    \item Máquina pessoal
        \begin{itemize}
            \item Sistema operacional: Ubuntu 20.04 LTS
            \item Processador: Intel i7-10700, 8 núcleos, 4,8 GHz
            \item Memória RAM: 32Gb
        \end{itemize}
        Esta máquina foi utilizada para iniciar duas máquinas virtuais que serão usadas 
        como o atacante e a vítima.
    \item Macbook 
        \begin{itemize}
            \item Sistema operacional: macOS Monterey - 12.0.1
            \item Processador: M1, 8 núcleos, 3,2 GHz
            \item Memória RAM: 8Gb
        \end{itemize}        
        Esta máquina foi utilizada para rodar os experimentos com Apache Spark, os quais 
        serão comparados com os resultados dos computadores de placa única.
\end{itemize}


\subsection{Máquinas virtuais}

Aqui estão as duas máquinas virtuais que foram usadas: o atacante e a vítima, como mostrada na Figura \ref{fig:arquitetura_ataque}. 
Elas foram criadas na máquina pessoal.

\begin{itemize}
    \item Atacante
        \begin{itemize}
            \item Sistema operacional: Kali Linux 2021.2
            \item Processador: Intel i7-10700, 4 núcleos, 4,8 GHz
            \item Memória RAM: 4Gb
        \end{itemize}
    \item Vítima
        \begin{itemize}
            \item Sistema operacional: Ubuntu 20.04 LTS
            \item Processador: Intel i7-10700, 4 núcleos, 4,8 GHz
            \item Memória RAM: 4Gb
        \end{itemize}        
\end{itemize}



\subsection{Computador de placa única}

Neste trabalho um Raspberry Pi foi utilizado, nele executamos as tarefas de treino e classificação
dos logs.

\begin{itemize}
    \item Raspberry Pi
        \begin{itemize}
            \item Sistema operacional: Raspberry Pi OS - 10.9
            \item Processador: Quad Core 1,2GHz Broadcom BCM2837
            \item Memória RAM: 1Gb
        \end{itemize}
\end{itemize}

\section{Ambiente de programação}
\begin{itemize}
    \item Google Colab
        \begin{itemize}
            \item Sistema operacional: Ubuntu 18.04.5 LTS
            \item Processador: Intel(R) Xeon(R) CPU, 1 núcleo, 2,20GHz
            \item Memória RAM: 16Gb
        \end{itemize} 
        Este ambiente foi utilizado para escrever os notebooks com os modelos e compartilhar os resultados
        parciais de forma eficaz. A configuração de hardware apresentada acima é a configuração padrão na data 
        que este trabalho foi realizado.
\end{itemize}

\section{Coleta de dados}

A fonte primária de dados deste trabalho são logs de servidores web, especificamente,
servidores HTTP Apache. Eles são úteis porque seguem um padrão, como mostrado abaixo:

\begin{verbatim}
127.0.0.1 - - [28/F...:28 -0400] "GET /url1 HTTP/1.0" 200 9 "-" "ApacheB"
127.0.0.1 - - [28/F...:28 -0400] "GET /url3 HTTP/1.0" 200 9 "-" "ApacheB"
127.0.0.1 - - [28/F...:28 -0400] "GET /url1 HTTP/1.0" 200 9 "-" "ApacheB"
127.0.0.1 - - [28/F...:28 -0400] "GET /url2 HTTP/1.0" 200 9 "-" "ApacheB"
127.0.0.1 - - [28/F...:28 -0400] "GET /url2 HTTP/1.0" 200 9 "-" "ApacheB"
\end{verbatim}

Nele encontramos os seguintes dados: o endereço ip de acesso, a data, o método HTTP que foi utilizado, 
a URL de acesso, o código HTTP de retorno, a quantidade de bytes retornada e o agente que realizou a requisição.

Por exemplo, na última linha das sequências apresentadas acima, temos os seguintes dados:

\begin{itemize}
    \item 127.0.0.1: endereço IP de origem, neste caso, o mesmo computador onde está a aplicação Apache.
    \item 28/F...:28 -0400: data e hora da requisição
    \item GET: é o verbo HTTP que foi utilizado. Ele significa que o usuário quer obter dados do servidor.
    \item /url2 HTTP/1.0: A URL que o usuário quer acessar e a versão do protocolo HTTP usado.
    \item 200: é código HTTP de resposta, neste caso, representa sucesso.
    \item 9: a quantidade de bytes retornados pela requisição. 
    \item ApacheB: Representa o agente que realizou a requisição, aqui em específico ApacheB é uma
    abreviação para ApacheBenchmark o agente de um utilitário chamado ab \footnote{\url{https://httpd.apache.org/docs/2.4/programs/ab.html}}, 
    que é usado para automatizar um certa quantidade de requisições a uma certa URL.
    Nesse campo, em geral, estão as informações do navegador, como Google Chrome ou Firefox.
\end{itemize}


\subsection{Dados simulados}

No início do projeto não foi possível encontrar logs reais que fossem públicos. Algumas fontes
consideradas foram o: Kaggle \footnote{\url{https://www.kaggle.com/datasets}} e o IEEE Data Port 
\footnote{\url{https://ieee-dataport.org/}}. Por causa disso, tomamos a decisão de simular requisições maliciosas 
e não maliciosas para então coletar seus logs. Para simular tais requisições três condições devem 
ser satisfeitas pois pensamos que seria prudente encontrar em logs reais, são elas:

\begin{itemize}
    \item A quantidade de requisições não maliciosas deve ser consideravelmente
    superior a quantidade de requisições maliciosas. Isto é, os dados devem estar desbalanceados.
    \item Certas páginas devem ser mais acessadas do que outras, isso se dá por conta 
    de que em sites há páginas que recebem mais acessos do que as outras, por exemplo, a página inicial.
    \item Deve haver uma predominância de acessos vindo dos navegadores Google Chrome e Firefox pelo fato 
    deles estarem entre os navegadores mais usados no mundo \footnote{\url{https://gs.statcounter.com/browser-market-share/}}.
\end{itemize}

Para alcançar tais condições, os utilitários xsser, sqlmap e um crawler desenvolvido para 
este trabalho foi usado (mais informações no apêndice). As requisições foram feitas da seguinte maneira:

\begin{itemize}
    \item O utilitário xsser realiza requisições de ataques XSS.
    \item O utilitário sqlmap realiza requisições de SQL Injection.
    \item O crawler realiza as requisições não maliciosas
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{figuras/arquitetura_ataque.png}
    \caption{Arquitetura para simular as requisições. \label{fig:arquitetura_ataque}}    
\end{figure}

Os processos eram executados de modo que ao final, aproximadamente 10\% das requisições 
fossem maliciosas e 90\% não. Os acessos foram feitos a partir de máquinas separadas como 
mostrado na Figura \ref{fig:arquitetura_ataque}.

Na simulação o fator tempo foi arbitrariamente desconsiderado. E nos modelos ele não se mostrou 
como uma característica relevante, mas isso não descarta a possibilidade dele ser usado com uma possível
característica para classificar os dados.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{figuras/request_por_url.png}
    \caption{Requisições por URL. \label{fig:request_por_url}}    
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.7\textwidth]{figuras/request_por_tipo.png}
    \caption{Requisições por tipo. \label{fig:request_por_tipo}}    
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.7\textwidth]{figuras/requisicoes_por_navegador.png}
    \caption{Requisições por navegador. \label{fig:request_por_navegador}}    
\end{figure}

As figuras \ref{fig:request_por_url}, \ref{fig:request_por_tipo} e \ref{fig:request_por_navegador} resumem 
as requisições realizadas. Nota-se que os critérios estabelecidos foram satisfeitos. Por exemplo, na
Figura \ref{fig:request_por_url} há uma quantidade maior de requisições em certas URLs, na Figura 
\ref{fig:request_por_tipo} há mais requisições não maliciosas do que maliciosas e 
na Figura \ref{fig:request_por_navegador} vemos a predominância dos navegadores Google Chrome e 
Firefox. E por fim, como 
sabíamos a origem das requisições (xsser, sqlmap ou crawler) construir a fonte da verdade para estes 
dados foi uma tarefa trivial.

\subsection{Dados reais}

Em paralelo às simulações anteriores, procuramos logs de servidores reais para que os modelos 
encontrados fossem testados e validades neles. 

Para isso entramos em contato com os autores dos artigos mencionados no Capítulo 2, e 
perguntamos quais dados foram usados em seus respectivos artigos. Jaron Fontaine, um dos autores
do artigo \cite{ref:art6} nos respondeu com os dados utilizados e eles estavam disponíveis de
maneira pública. 

Os dados indicados fazem parte de um projeto chamado The Honeynet Project \footnote{\url{https://www.honeynet.org/}}. 
Trata-se de uma organização de pesquisa 
sem fins lucrativos, que tem como objetivo pesquisar e investigar os últimos ataques e desenvolver
ferramentas open source para melhorar a segurança da internet.

Os dados faziam parte de uma competição de segurança da informação, e foram coletados da seguintes maneira:

\begin{itemize}
    \item Uma aplicação web com múltiplos servidores foi disponibilizada publicamente.
    \item Escolheu-se alguns dos servidores para subir uma versão da aplicação 
    com falhas de segurança conhecidas.
    \item Então monitorou-se a atividade nesses servidores com falhas para detectar intrusões.
\end{itemize}

Apesar dos dados serem reais, a competição tratava-se de identificar, a partir dos logs, quais requisições 
eram maliciosas e também se o ataque foi realizado com sucesso ou não. 

Nesse sentido, isso foi um desafio, dado que a fonte da verdade não era pública e a quantidade de logs 
coletados é consideravelmente grande. Então classificá-los manualmente foi necessário e para 
isso foi utilizado o script que se encontra no apêndice.

No fim, foram classificadas aproximadamente 10000 linhas e este conjunto de logs foi utilizado para validar os modelos em dados
reais.

\subsection{Estruturando os logs}

Os logs em seu formato bruto não podem ser usados como entradas para modelos de aprendizagem
de máquina, então um pré-processamento foi necessário. Por conta do padrão mencionado no  início deste capítulo, 
foi possível criar um script que os estruturasse. Abaixo um trecho de código
que foi usado nessa tarefa:

\begin{lstlisting}[language=Python]
def transformLogFileToDataframe(logFilePath, isMalicious):
    lineformat = re.compile(r"""(?P<ipaddress>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}) - - \[(?P<dateandtime>\d{2}\/[a-z]{3}\/\d{4}:\d{2}:\d{2}:\d{2} (\+|\-)\d{4})\] ((\"(GET|POST) )(?P<url>.+)(http\/[1-2]\.[0-9]")) (?P<statuscode>\d{3}) (?P<bytessent>\d+) (?P<refferer>-|"([^"]+)") (["](?P<useragent>[^"]+)["])""", re.IGNORECASE)

    logFile = open(logFilePath)

    logs_data = []

    for l in logFile.readlines():
        data = re.search(lineformat, l)

        if data is None:
            print("Falha ao fazer o parse da linha {} do arquivo {}. Pulando..".format(l, logFile))
            continue

        datadict = data.groupdict()
        datadict["malicious"] = isMalicious
        logs_data.append(datadict)

    logFile.close()

    df = pd.DataFrame(logs_data)

    df["statuscode"] = df["statuscode"].apply(int)
    df["qtd_query_params"] = df["url"].apply(quantidade_de_params_na_query)

    return df
\end{lstlisting}

No código acima, primeiro criamos uma expressão regular que irá capturar as informações de cada linha do log. 
Em seguida, abrimos o arquivo de log, aplicamos a expressão regular e em caso de sucesso, adicionamos ao 
dicionário logs\_data que irá guardar as informações de cada linha. Ao final, temos o log em um formato tabular
que pode ser usado nos modelos de aprendizagem de máquina.